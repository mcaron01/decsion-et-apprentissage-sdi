{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP3 : Logistic regression\n",
    "\n",
    "The purpose of this tutorial is to implement and use the Logistic Regression for binary classification. We will apply this\n",
    "method to the problem of handwritten characters to learn how to\n",
    "distinguish two numbers (here 5 and 6).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import linalg as la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic regression, IRLS algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary question: the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have a look at the function `regression_logistique.m` and locate the main steps of the algorithm you have been taught (see course).\n",
    "You can comment the code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regression_logistique(X,t,Nitermax=20,eps_conv=1e-3):\n",
    "    '''Entrees :\n",
    "    X = [ones(N_train,1) x_train];\n",
    "    t = class_train \n",
    "    Nitermax = nombre maximale d'itérations (20 par défaut)\n",
    "    eps_conv = critère de convergence sur norm(w-w_old)/norm(w) ; \n",
    "    eps_conv=1e-3 par défaut\n",
    "    \n",
    "    Sorties : \n",
    "    w : vecteur des coefficients de régression logistique\n",
    "   Niter : nombre d'itérations utilisées effectivement\n",
    "   \n",
    "   Fonction de régression logistique pour la classification binaire.\n",
    "   \n",
    "   Utilisation :\n",
    "       Nitermax = 50\n",
    "       eps_conv = 1e-4\n",
    "       [w,Niter] = regression_logistique(X,t,Nitermax,eps_conv)\n",
    "    '''\n",
    "    N_train = X.shape[0]\n",
    "\n",
    "    #initialisation : 1 pas de l'algorithme IRLS\n",
    "    w = np.zeros((X.shape[1],))\n",
    "    w_old = w \n",
    "    y = 1/2*np.ones((N_train,))\n",
    "    R = np.diag(y*(1-y))   # diag(y_n(1-y_n))\n",
    "    z = X.dot(w_old)-la.inv(R).dot(y-t)\n",
    "    w = la.inv(X.T.dot(R).dot(X)).dot(X.T).dot(R).dot(z)\n",
    "\n",
    "    # boucle appliquant l'algortihme de Newton-Raphson\n",
    "    Niter = 1\n",
    "    while ( (la.norm(w-w_old)/la.norm(w)>eps_conv) | (Niter<Nitermax) ):\n",
    "        Niter = Niter+1\n",
    "        y = 1/(1+np.exp(-X.dot(w)))\n",
    "        R = np.diag(y*(1-y))  \n",
    "        w_old = w \n",
    "        z = X.dot(w_old)-la.inv(R).dot(y-t) \n",
    "        w = la.inv(X.T.dot(R).dot(X)).dot(X.T).dot(R).dot(z)\n",
    "         \n",
    "    return w, Niter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading & preparing synthetic data\n",
    "\n",
    "Load the training and test data sets `synth_train.txt`\n",
    "and `synth_test.txt`. The targets t belong to {1,2} and the features  \n",
    "x belong to R^2. \n",
    "\n",
    "We have 100 training samples and 200 test samples\n",
    "\n",
    "* the 1st column contains the label of each sample, \n",
    "* columns 2 and 3 contain the coordinate of each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training set\n",
    "synth_train = np.loadtxt('synth_train.txt') \n",
    "class_train = synth_train[:,0]\n",
    "class_train_1 = np.where(synth_train[:,0]==1)[0]\n",
    "class_train_2 = np.where(synth_train[:,0]==2)[0]\n",
    "x_train = synth_train[:,1:]\n",
    "N_train = np.size(x_train,axis=0)\n",
    "\n",
    "# Test set\n",
    "synth_test = np.loadtxt('synth_test.txt')\n",
    "class_test = synth_test[:,0]\n",
    "class_test_1 = np.where(synth_test[:,0]==1)[0]\n",
    "class_test_2 = np.where(synth_test[:,0]==2)[0]\n",
    "x_test = synth_test[:,1:]\n",
    "N_test = np.size(x_test,axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing features for logistic regression (binary classification)\n",
    "First, we prepare the feature matrix and the target vector associated to \n",
    "the training and test sets:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((np.ones((N_train,1)),x_train))\n",
    "t = 2-class_train   # 0 if class=2, 1 if class=1\n",
    "\n",
    "X_test = np.hstack((np.ones((N_test,1)),x_test))\n",
    "t_test = 2-class_test   # 0 if class=2, 1 if class=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 : the logistic function of decision\n",
    "\n",
    "1. Use the function `regression_logistique.m` to estimate the logistic\n",
    "regression vector `w`. *Indication : use `Nitermax = 50;\n",
    "eps_conv=1e-3;`.*\n",
    "2. Compute the decision function $f(x) = argmax_k P(C_k|x)$ on the test set\n",
    "to get the classification results. Recall that $y_n=\\sigma(w^T x)$ (logistic function)\n",
    "and that *using vectors* you may directly write $y=\\sigma(Xw)$, with the\n",
    "column of ones in X.\n",
    "3. Display the results by plotting the points from both the training set\n",
    "and the test set.\n",
    "4. Write the equation which defines the decision boundary.\n",
    "5. Artificially add a few points to the training set far from the decision boundary to check the robustness of logistic regression to outliers. Check the behaviour of LDA for comparison in this case and comment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 1\n",
    "w, Niter = regression_logistique(X, t)\n",
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can draw the decision boundary $w^Tx = 0$ by using: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First compute w... then: \n",
    "x1 = np.linspace(-2.5,1.5,10) \n",
    "x2 = (-w[0]-w[1]*x1)/w[2]\n",
    "plt.plot(x1,x2,'k--')\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Application: handwritten digits recognition 5 & 6\n",
    "We load 2 matrices which contain each a sequence of examples of 16x16 images \n",
    "of handwritten digits which are 5 and 6 here. Each line of the matrix\n",
    "contains 256 pixel values coding for the gray level of a 16x16 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_5 = np.loadtxt('train_5.txt',delimiter=',')   # 556 samples\n",
    "train_6 = np.loadtxt('train_6.txt',delimiter=',')   # 664 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAD6VJREFUeJzt3X+sV/V9x/HXawKrUlZxWvwB8QcajJY5r0SpXZwOdMhU\n0NQEYjdWmxCzselibWk0VpaYrOvW/eiaVqZubvMHmQVLGhGJVRfjZAKiYLEV8E5R6o+VYJ0Ri7z3\nx/fc5XK993LP5/zgXj7PR3Lz/XXe9/PmfO+L8/2e7/ecjyNCAPLzKwe7AQAHB+EHMkX4gUwRfiBT\nhB/IFOEHMkX4gUwRfiBThB/I1Kg2B7Od9HXCsWPHlq4ZN25cylBJJkyYkFT3/vvvJ9Vt27atdM2+\nffuSxsLIExEeynKthj/V1KlTS9dcdNFFDXTSvxtvvDGp7tlnn02qu/rqq0vXvPfee0lj4dDFy34g\nU5XCb3uW7Z/Y3mp7cV1NAWhecvhtHybpO5IulXSGpPm2z6irMQDNqrLlP1fS1ojYHhEfSnpA0px6\n2gLQtCrhP0HSa71u7yjuAzACVNnb39/HCR/7KM/2QkkLK4wDoAFVwr9D0qRetydKeqPvQhGxVNJS\nKf1zfgD1q/Ky/1lJp9k+2fYYSfMkraynLQBNS97yR8Re24skrZZ0mKS7I+LF2joD0KhK3/CLiIcl\nPVxTLwBaxDf8gEwRfiBTbvO8/al7+1esWFG6Zu7cuSlDjQjvvPNO6ZqnnnoqaazHH388qW64zwcx\nefLkpLrx48cn1S1ZsqR0zfbt25PGGupRfWz5gUwRfiBThB/IFOEHMkX4gUwRfiBThB/IFOEHMkX4\ngUwRfiBThB/IFOEHMjUiDuw544zyZwS/5ZZbUobS/Pnzk+pSpM6is2vXrtI1xx57bNJYo0ePTqrD\n/jZs2FC65pxzzkkaiwN7AAyK8AOZIvxApqpM1zXJ9uO2t9h+0fb1dTYGoFlVTuC5V9KNEbHB9jhJ\n622viYgf19QbgAYlb/kjYmdEbCiu/0LSFjFdFzBiVDp1dw/bJ0k6W9Lafh5jui5gGKocftuflPR9\nSTdExLt9H2e6LmB4qrS33/ZodYJ/b0Qsr6clAG2osrffku6StCUivlVfSwDaUGXL/zlJvy/pd2xv\nLH5m19QXgIZVmajzKUlD+g4xgOGHb/gBmRoRR/WlmD59elLd008/Xbqms/ujvOuuuy6p7o477ihd\nM3HixKSxZsyYkVR3+OGHJ9UdqjZv3ly6JnWKNY7qAzAowg9kivADmSL8QKYIP5Apwg9kivADmSL8\nQKYIP5Apwg9kivADmSL8QKYO2QN7Vq1alVQ3a9as0jXd3d1JY51++ulJdXv27EmqQx44sAfAoAg/\nkCnCD2SqcvhtH2b7Ods/rKMhAO2oY8t/vTqz9QAYQaqet3+ipN+TdGc97QBoS9Ut/99K+oqkfTX0\nAqBFVSbtuEzSWxGx/gDLLbS9zva61LEA1K/qpB1X2O6W9IA6k3f8W9+FImJpREyLiGkVxgJQsypT\ndH8tIiZGxEmS5kn6UUR8obbOADSKz/mBTFWeoluSIuIJSU/U8bsAtIMtP5CpWrb8TTv//PNL16Qc\nnZdq2bJlSXUcnYeDiS0/kCnCD2SK8AOZIvxApgg/kCnCD2SK8AOZIvxApgg/kCnCD2SK8AOZIvxA\npgg/kKkRMVffmjVrStfMnDkzZagkq1evbrVu5cqVpWu2bduWNBZGHubqAzAowg9kquqkHUfaftD2\nS7a32P5sXY0BaFbVM/n8naRHIuLztsdIOqKGngC0IDn8tn9N0gWS/lCSIuJDSR/W0xaAplV52X+K\npLcl/VMxS++dtsfW1BeAhlUJ/yhJXZK+GxFnS/pfSYv7LsR0XcDwVCX8OyTtiIi1xe0H1fnPYD9M\n1wUMT1Wm6/qZpNdsTynumiHpx7V0BaBxVff2/4mke4s9/dslfbF6SwDaUCn8EbFREi/ngRGIb/gB\nmRoRB/bcd999pWvmz5+fMtSI8MEHH5Su2bhxY9JYS5YsSap75JFHkupQHQf2ABgU4QcyRfiBTBF+\nIFOEH8gU4QcyRfiBTBF+IFOEH8gU4QcyRfiBTBF+IFOEH8jUiDiqb9So8qcduPLKK1OG0vr160vX\n7Nu3L2ms448/PqnuvPPOK12zYMGCpLGmTp2aVHfrrbeWrrn99tuTxsL+OKoPwKAIP5CpqtN1/Znt\nF21vtn2/7U/U1RiAZiWH3/YJkv5U0rSI+IykwyTNq6sxAM2q+rJ/lKTDbY9SZ56+N6q3BKANVc7b\n/7qkv5L0qqSdknZHxKN1NQagWVVe9o+XNEfSyZKOlzTW9hf6WY7puoBhqMrL/pmSXomItyPil5KW\nSzq/70JM1wUMT1XC/6qk6baPsG11puvaUk9bAJpW5T3/WnUm59wgaVPxu5bW1BeAhlWdruvrkr5e\nUy8AWsQ3/IBMEX4gUyPiqD5UN3r06KS6ZcuWJdXNnTu3dE1XV1fSWKnzEB6qOKoPwKAIP5Apwg9k\nivADmSL8QKYIP5Apwg9kivADmSL8QKYIP5Apwg9kivADmeLAHgzqzDPPTKrbtGlT6Zru7u6ksSZP\nnly6ps2/+7ZxYA+AQRF+IFMHDL/tu22/ZXtzr/uOsr3G9svF5fhm2wRQt6Fs+f9Z0qw+9y2W9FhE\nnCbpseI2gBHkgOGPiP+Q9PM+d8+RdE9x/R5J5U/bAuCgSn3PPyEidkpScfnp+loC0IZKp+4eCtsL\nJS1sehwA5aRu+d+0fZwkFZdvDbQg03UBw1Nq+FdKWlBcXyDpB/W0A6AtQ/mo735J/ylpiu0dtr8k\n6S8kXWz7ZUkXF7cBjCAHfM8fEfMHeGhGzb0AaBHf8AMyRfiBTDX+UR9GttSj3+whHVi2n2OOOSZp\nrDFjxpSu2bNnT9JYhxK2/ECmCD+QKcIPZIrwA5ki/ECmCD+QKcIPZIrwA5ki/ECmCD+QKcIPZIrw\nA5kaEQf2TJo0qXTNQw89lDTWzJkzS9fs2rUraayR4JprrmltrFdeeSWpbu/evTV3kge2/ECmCD+Q\nKcIPZCp1rr5v2n7J9gu2V9g+stk2AdQtda6+NZI+ExG/Iemnkr5Wc18AGpY0V19EPBoRPbtYn5E0\nsYHeADSojvf810paNdCDthfaXmd7XQ1jAahJpc/5bd8saa+kewdaJiKWSlpaLJ92NkgAtUsOv+0F\nki6TNCNST/EK4KBJCr/tWZK+Kum3I+L9elsC0IbUufr+QdI4SWtsb7T9vYb7BFCz1Ln67mqgFwAt\n4ht+QKYO2aP6urq6ksY666yzStc88cQTSWOlmjBhQumam266KWmsRYsWJdWlWL58eVLdRx99VHMn\neWDLD2SK8AOZIvxApgg/kCnCD2SK8AOZIvxApgg/kCnCD2SK8AOZIvxApgg/kCnCD2TKbZ6BK/Uc\nfrZL16xevTplKE2ZMqV0TXd3d9JYr776alLdhRdeWLpm4sR2T7D83HPPla656qqrksZKXf+HqogY\nUmDY8gOZIvxAppKm6+r12Jdth+2jm2kPQFNSp+uS7UmSLpaU9sYVwEGVNF1X4W8kfUUS5+wHRqDU\n8/ZfIen1iHj+QHvibS+UtDBlHADNKR1+20dIulnSJUNZnum6gOEpZW//ZEknS3redrc6M/RusH1s\nnY0BaFbpLX9EbJL06Z7bxX8A0yLinRr7AtCw1Om6AIxwqdN19X78pNq6AdAavuEHZGpEHNjTpuuv\nv750zeWXX5401qmnnppUd+KJJ5auSTnQRpJuu+22pLonn3yydM3u3buTxsL+OLAHwKAIP5Apwg9k\nivADmSL8QKYIP5Apwg9kivADmSL8QKYIP5Apwg9kivADmSL8QKbaPqrvbUn/PcDDR0saDmcDoo/9\n0cf+hnsfJ0bEMUP5Ba2GfzC210XENPqgD/popw9e9gOZIvxApoZT+Jce7AYK9LE/+tjfIdPHsHnP\nD6Bdw2nLD6BFrYbf9izbP7G91fbifh7/VdvLisfX2j6pgR4m2X7c9hbbL9r+2Bk7bV9oe7ftjcXP\nrXX30WusbtubinHW9fO4bf99sU5esN1V8/hTev07N9p+1/YNfZZpbH30NwW87aNsr7H9cnE5foDa\nBcUyL9te0EAf37T9UrHeV9g+coDaQZ/DGvq4zfbrvdb/7AFqB83Xx0REKz+SDpO0TdIpksZIel7S\nGX2W+SNJ3yuuz5O0rIE+jpPUVVwfJ+mn/fRxoaQftrReuiUdPcjjsyWtkmRJ0yWtbfg5+pk6nxW3\nsj4kXSCpS9LmXvf9paTFxfXFkr7RT91RkrYXl+OL6+Nr7uMSSaOK69/or4+hPIc19HGbpC8P4bkb\nNF99f9rc8p8raWtEbI+IDyU9IGlOn2XmSLqnuP6gpBk+0DTAJUXEzojYUFz/haQtkk6oc4yazZH0\nL9HxjKQjbR/X0FgzJG2LiIG+iFW76H8K+N5/B/dImttP6e9KWhMRP4+IXZLWSJpVZx8R8WhE7C1u\nPqPOvJSNGmB9DMVQ8rWfNsN/gqTXet3eoY+H7v+XKVb6bkm/3lRDxduKsyWt7efhz9p+3vYq22c2\n1YOkkPSo7fXFdOZ9DWW91WWepPsHeKyt9SFJEyJip9T5z1q95obspc31IknXqvMKrD8Heg7rsKh4\n+3H3AG+DSq+PNsPf3xa870cNQ1mmFrY/Ken7km6IiHf7PLxBnZe+Z0n6tqSHmuih8LmI6JJ0qaQ/\ntn1B31b7qal9ndgeI+kKSf/ez8Ntro+havNv5WZJeyXdO8AiB3oOq/quOrNj/6aknZL+ur82+7lv\n0PXRZvh3SJrU6/ZESW8MtIztUZI+pbSXQIOyPVqd4N8bEcv7Ph4R70bEe8X1hyWNtn103X0Uv/+N\n4vItSSvUefnW21DWWx0ulbQhIt7sp8fW1kfhzZ63NsXlW/0s08p6KXYkXibpmijeXPc1hOewkoh4\nMyI+ioh9kv5xgN9fen20Gf5nJZ1m++RiKzNP0so+y6yU1LPX9vOSfjTQCk9V7EO4S9KWiPjWAMsc\n27Ovwfa56qyn/6mzj+J3j7U9rue6OjuYNvdZbKWkPyj2+k+XtLvnJXHN5muAl/xtrY9eev8dLJD0\ng36WWS3pEtvji5fBlxT31cb2LElflXRFRLw/wDJDeQ6r9tF7H8+VA/z+oeRrf3XsoSyxJ3O2OnvX\nt0m6ubjvz9VZuZL0CXVedm6V9F+STmmgh99S5+XQC5I2Fj+zJV0n6bpimUWSXlRnj+kzks5vaH2c\nUozxfDFezzrp3YslfadYZ5skTWugjyPUCfOnet3XyvpQ5z+cnZJ+qc7W60vq7Od5TNLLxeVRxbLT\nJN3Zq/ba4m9lq6QvNtDHVnXeR/f8nfR8EnW8pIcHew5r7uNfi+f+BXUCfVzfPgbK12A/fMMPyBTf\n8AMyRfiBTBF+IFOEH8gU4QcyRfiBTBF+IFOEH8jU/wEeooavBb8iBQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108590b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Digit 5\n",
    "n=9;\n",
    "I = np.reshape(train_5[n,:],(16,16))\n",
    "\n",
    "plt.imshow(I,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMkX4gUwRfiBThB/IFOEHMkX4gUz9H0abLwO7AIctAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1085bd550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Digit 6\n",
    "n=5;\n",
    "I = reshape(train_6[n,:],(16,16))\n",
    "\n",
    "plt.imshow(I,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating the training and test sets\n",
    "\n",
    "We keep in the training set the 145 first images of 5s and the 200 first\n",
    "images of 6s:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_brut = np.vstack((train_5[:145,:], train_6[:200,:]))\n",
    "N_train = np.size(x_train_brut,axis=0)\n",
    "class_train = np.ones((345,1))   # label 1 for digit 6\n",
    "class_train[:145] = 0       # label 0 for digit 5\n",
    "\n",
    "x_test_brut = np.vstack((train_5[145:,:], train_6[200:,:]))\n",
    "N_test = np.size(train_5,axis=0)+np.size(train_6,axis=0)-N_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: logistic regression to classify 5 & 6\n",
    "\n",
    "1. Note that pixel values are between -1 and 1 by using the functions\n",
    " `min(I(:))` and `max(I(:))`.\n",
    "2. Identify the indices of the most significant pixels, which are defined \n",
    "as having a standard deviation greater than 0.5 here. We denote by `lis_sig`\n",
    "the list of positions of these significant pixels in the image vector.\n",
    "_Indication : the function `std` gives the standard deviation (columnwise\n",
    "in matrices) and you should find 173 pixel positions.\n",
    "3. Show a binary image to locate these pixels.\n",
    "_Indication : `Isig = zeros(16); Isig(list_sig)=1; Isig=Isig';`._\n",
    "4. Define the training set `x_train` from `x_train_brut` from the significant pixels only.\n",
    "5. Do the same with `x_test_brut` to extract `x_test`.\n",
    "6. Use `regression_logistique.m` to estimate the logistic regression vector\n",
    "`w` from the training set `x_train`. \n",
    "Choose `Nitermax = 13; eps_conv = 1e-3;`\n",
    "7. Compute the decision function and the labels of the test set `x_test`. \n",
    "_Indication : do not forget the column of ones !_\n",
    "8. Estimate the classification error rate by using :\n",
    "`erreur = sum(abs(class-class_test))/N_test;`.\n",
    "9. Locate some misclassified examples and visualize the corresponding image.\n",
    "Comment on your results and observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Logistic regression using `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. **Go to** http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html for a presentation of the logistic regression model in `scikit-learn`.\n",
    "\n",
    "2. **Apply** it to the present data set.\n",
    "\n",
    "3. **Comment** on the use of logistic regression.\n",
    "\n",
    "*Indication : you may have a look at* \n",
    "\n",
    "a) Theory : http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&doc=exercises/ex5/ex5.html\n",
    "\n",
    "b) Video :  https://www.coursera.org/learn/machine-learning/lecture/4BHEy/regularized-logistic-regression \n",
    "\n",
    "c) Example : http://scikit-learn.org/stable/auto_examples/exercises/plot_digits_classification_exercise.html#sphx-glr-auto-examples-exercises-plot-digits-classification-exercise-py\n",
    "\n",
    "*for a short presentation of regularized logistic regression.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include your code here\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentaires :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
